\chapter{Experimental Evaluation}

This chapter presents a comprehensive evaluation of the proposed class-based normalization approach for environmental pollution detection using deep learning. The experiments were conducted using a dataset comprising five distinct spectrometer chips, each annotated with four classes where class 4 represents non-polluted conditions and serves as the statistical reference for normalization.

\section{Experimental Setup}

\subsection{Dataset Configuration and Cross-Hardware Validation Protocol}

The experimental evaluation employs a leave-one-chip-out cross-validation protocol designed to assess the robustness of cross-hardware generalization capabilities. The dataset comprises five distinct spectrometer chips, each containing 400 samples distributed equally across four environmental conditions. The experimental configuration segregates chips 1-4 as the training corpus, totaling 1600 samples, while chip 5 serves as the completely unseen test hardware with 400 samples.

The training dataset from chips 1-4 is further partitioned following a 70-30 split strategy, resulting in 1120 samples for model optimization and 480 samples for validation and hyperparameter tuning. This protocol simulates realistic deployment scenarios where models trained on reference hardware must demonstrate robust performance when deployed on new, unseen spectrometer devices with potentially different calibration characteristics and sensor responses.

\subsection{Model Architecture and Training Configuration}

The proposed pipeline employs a two-stage architecture comprising a LinearDenoiser autoencoder followed by a convolutional classifier. The LinearDenoiser implements a symmetric encoder-decoder structure with encoding layers transitioning through dimensions 33 → 32 → 64 → 32, while the decoder reconstructs the input through 32 → 64 → 128 → 33 dimensions. The architecture incorporates GELU activation functions and batch normalization layers to enhance feature learning stability and convergence characteristics.

The classifier component employs a convolutional neural network architecture with adaptive pooling mechanisms and fully connected layers optimized for four-class environmental classification. The training procedure implements distinct early stopping strategies to prevent overfitting, with autoencoder training employing 15-epoch patience for early stopping and 7-epoch patience for learning rate reduction, while classifier training utilizes more aggressive 6-epoch and 3-epoch patience values respectively.

Training hyperparameters were configured to ensure stable convergence across the heterogeneous hardware configurations. The optimization employed Adam optimizer with an initial learning rate of 1×10⁻³, batch size of 32, and ReduceLROnPlateau scheduler for adaptive learning rate adjustment. Maximum training epochs were set to 500 to accommodate potential convergence variations across different chips, with model checkpointing preserving optimal states based on validation loss minimization.

\section{Class-Based Normalization Methodology}

The core innovation of this work lies in the implementation of an asymmetric reference-based normalization strategy that leverages Class 4 statistics as hardware-specific calibration anchors. The normalization transformation is formally defined as:

\begin{equation}
\tilde{\mathbf{x}}^{(c)}_i = 
\begin{cases}
\displaystyle \frac{\mathbf{x}^{(c)}_i - \boldsymbol{\mu}^{(c)}_4}{\boldsymbol{\sigma}^{(c)}_4}, & \text{if } y_i \in \{1, 2, 3\} \\[0.3em]
\mathbf{x}^{(c)}_i, & \text{if } y_i = 4
\end{cases}
\label{eq:class_based_normalization}
\end{equation}

where $\mathbf{x}^{(c)}_i$ represents the raw spectral measurement from chip $c$, $\boldsymbol{\mu}^{(c)}_4$ and $\boldsymbol{\sigma}^{(c)}_4$ denote the mean and standard deviation computed exclusively from Class 4 samples of chip $c$, and $y_i$ indicates the class label. This formulation ensures that Class 4 samples remain unnormalized, serving as stable reference anchors, while pollution classes 1-3 are standardized relative to their chip-specific clean air baseline.

The asymmetric treatment addresses fundamental challenges in cross-hardware spectral analysis by ensuring that clean air conditions maintain consistent representation across devices while pollution signatures are normalized relative to their local environmental baseline. This approach effectively decouples hardware-specific calibration drift from environmental signal variations, enabling robust cross-device model deployment.

\section{Performance Evaluation and Results Analysis}

\subsection{Classification Performance Metrics}

The trained model demonstrates strong classification performance across both training and test configurations, validating the effectiveness of the proposed normalization approach. Training set evaluation reveals an overall accuracy of 80.9\%, with macro-averaged precision, recall, and F1-score of 81.0\%, 80.9\%, and 80.1\% respectively. The per-class training performance exhibits distinct patterns, with Class 1 achieving 68.2\% precision and 83.6\% recall, Class 2 demonstrating 73.7\% precision with 48.9\% recall, Class 3 attaining 82.0\% precision and 91.1\% recall, and Class 4 maintaining perfect 100\% performance across all metrics.

Cross-hardware generalization assessment on the unseen chip 5 yields an overall test accuracy of 65.3\%, representing a 15.6 percentage point decrease from training performance. This degradation reflects the inherent challenges of cross-device deployment while demonstrating acceptable generalization capabilities. Test set macro-averaged metrics achieve 57.8\% precision, 65.3\% recall, and 59.5\% F1-score, indicating successful knowledge transfer despite hardware heterogeneity.

The per-class test performance reveals differential generalization patterns across pollution types. Class 1 maintains reasonable performance with 52.8\% precision and 75.0\% recall, while Class 2 exhibits significant degradation to 18.2\% precision and 4.0\% recall, suggesting this environmental condition presents the greatest cross-hardware variability. Class 3 demonstrates robust generalization with 60.3\% precision and 82.0\% recall, indicating stable spectral characteristics across devices. Class 4 maintains perfect classification accuracy, validating the effectiveness of the reference-based normalization strategy.

\subsection{Confusion Matrix Analysis and Error Patterns}

The confusion matrices provide detailed insights into classification decision patterns and error modes across training and test configurations. Training set confusion matrix analysis reveals that the primary classification challenges occur between pollution classes, with Class 2 experiencing the highest misclassification rates. Specifically, 99 Class 2 samples are misclassified as Class 1, while 44 samples are incorrectly assigned to Class 3, indicating significant spectral overlap between these environmental conditions.

Test set confusion matrix evaluation exposes amplified cross-class confusion under cross-hardware conditions. Class 2 demonstrates severe degradation with only 4 correct classifications out of 100 samples, while 57 samples are misclassified as Class 1 and 39 as Class 3. This pattern suggests that Class 2 environmental signatures exhibit the highest sensitivity to hardware variations, potentially requiring specialized calibration procedures or additional training data from diverse hardware configurations.

The confusion patterns reveal systematic biases in cross-hardware classification, with pollution classes demonstrating increased confusion while Class 4 maintains perfect separation. This observation supports the fundamental premise of the reference-based normalization approach, where clean air conditions provide stable cross-device anchors while pollution signatures require careful calibration relative to local baselines.

\section{Feature Space Transformation Analysis}

\subsection{Progressive Feature Refinement Through Processing Pipeline}

The effectiveness of the proposed approach is demonstrated through systematic analysis of feature space transformations at each processing stage. The normalized training data exhibits dramatically improved class separability compared to raw spectral measurements, with Class 4 establishing a clear reference baseline around normalized values while pollution classes demonstrate distinct negative deflections relative to this anchor.

The normalization process creates linear separability between clean conditions and pollution classes, with Class 1 samples clustering around -0.5 to 0.3 normalized units, Class 2 samples spanning -0.7 to 0.2 units, and Class 3 samples ranging from -0.6 to 0.0 units. This structured separation validates the theoretical foundation of using Class 4 statistics as normalization anchors, effectively transforming overlapping raw signals into linearly separable feature distributions.

Test set normalized features demonstrate consistent transformation patterns despite hardware differences, with Class 4 maintaining stable positive values around 0.6 to 0.9 normalized units while pollution classes exhibit systematic negative deflections. The preservation of relative class positioning across hardware configurations confirms the robustness of the chip-specific normalization strategy.

\subsection{Autoencoder Denoising Effects and Feature Enhancement}

The denoising autoencoder stage provides additional feature refinement beyond normalization alone, as evidenced by the dramatic transformation in feature space characteristics. Denoised features exhibit substantially reduced variance and enhanced cluster compactness across all classes, with Class 4 forming extremely tight clusters around 0.8 denoised units while pollution classes maintain near-zero values with minimal inter-class overlap.

The autoencoder successfully removes noise artifacts and hardware-specific variations while preserving essential class-discriminative information. The denoised test features demonstrate remarkable consistency with training patterns, validating the generalization capabilities of the learned denoising transformation. The extreme compactness of denoised Class 4 clusters (approaching delta functions) indicates successful preservation of the reference baseline characteristics across all processing stages.

The progressive refinement from raw signals through normalization to denoising demonstrates the synergistic effectiveness of the proposed pipeline. Each stage contributes complementary benefits: normalization provides hardware-specific baseline alignment, while denoising removes residual noise and enhances class separability through learned feature transformations.

\section{Cross-Hardware Generalization Assessment}

\subsection{Hardware Variability and Model Robustness}

The experimental results provide comprehensive evidence for the proposed method's effectiveness in addressing cross-hardware variability challenges. The 15.6 percentage point accuracy decrease from training to test configurations represents acceptable performance degradation considering the complete hardware novelty of the test chip. This generalization gap falls within expected ranges for cross-device spectral analysis applications, particularly given the heterogeneous nature of spectrometer hardware characteristics.

Class-specific generalization patterns reveal differential sensitivity to hardware variations across environmental conditions. Class 3 demonstrates the most robust cross-hardware performance with only 8.5 percentage point F1-score degradation, suggesting this pollution type exhibits stable spectral signatures across device configurations. Conversely, Class 2 shows severe hardware sensitivity with 44.4 percentage point F1-score reduction, indicating this environmental condition requires enhanced calibration procedures or augmented training data diversity.

The maintenance of perfect Class 4 performance across all configurations validates the core hypothesis that clean air conditions provide stable cross-device reference points. This observation supports the feasibility of deploying reference-based normalization approaches in real-world environmental monitoring networks where hardware heterogeneity is inevitable.

\subsection{Practical Deployment Implications and Scalability}

The experimental outcomes demonstrate practical viability for multi-device environmental monitoring deployments. The automatic adaptation to chip-specific characteristics through Class 4 statistics computation eliminates manual calibration requirements, reducing operational complexity and deployment costs. The method's scalability is evidenced by consistent performance patterns across diverse hardware configurations without requiring device-specific model modifications.

The identification of Class 2 as the most challenging environmental condition provides actionable insights for system optimization. Enhanced training data collection focusing on Class 2 conditions across diverse hardware configurations could address the observed generalization limitations. Additionally, the robust performance of Classes 1 and 3 suggests the method's immediate applicability for detecting these specific pollution types in operational deployments.

\section{Limitations and Future Research Directions}

\subsection{Identified System Limitations}

The experimental evaluation reveals several limitations that warrant consideration for future developments. The severe performance degradation for Class 2 across hardware configurations indicates potential inadequacy in the current normalization approach for specific environmental conditions. This limitation may stem from intrinsic spectral characteristics of Class 2 pollution types that exhibit high sensitivity to hardware variations, requiring specialized preprocessing or augmented normalization strategies.

The evaluation's reliance on a single test chip limits the generalizability of cross-hardware conclusions. Comprehensive validation across multiple unseen hardware configurations would strengthen claims regarding method robustness and provide insights into performance variation bounds. Additionally, the current approach assumes availability of Class 4 measurements during deployment, which may not be guaranteed in all operational scenarios.

\subsection{Future Enhancement Opportunities}

Several research directions emerge from the current findings that could enhance system performance and applicability. Investigation of adaptive normalization strategies that account for Class 2-specific hardware sensitivities could address the observed performance limitations. Multi-reference normalization approaches utilizing multiple environmental conditions as calibration anchors might provide enhanced robustness for challenging pollution types.

The development of uncertainty quantification mechanisms could provide deployment confidence estimates, enabling system operators to assess prediction reliability under varying hardware conditions. Additionally, exploration of domain adaptation techniques specifically tailored for spectroscopic cross-hardware transfer could further improve generalization performance while reducing calibration requirements.

\section{Conclusions}

The experimental evaluation demonstrates the effectiveness of the proposed class-based normalization approach for cross-hardware environmental pollution detection. The method achieves successful generalization to unseen hardware configurations while maintaining interpretable and deployable system characteristics. The systematic analysis of feature space transformations validates the theoretical foundations of reference-based normalization, while practical performance metrics confirm operational viability for environmental monitoring applications.

The identification of class-specific hardware sensitivities provides valuable insights for system optimization and deployment planning. The robust performance of the majority of environmental conditions, coupled with perfect reference class accuracy, supports the method's immediate applicability in operational scenarios while highlighting specific areas requiring enhanced attention in future developments.